# intelligence/primitives/bands.py
"""
Bands, microstructure, and regime primitives (P001-P007)
Exact canonical signatures - DO NOT MODIFY
"""

import numpy as np
import pandas as pd
from scipy.stats import rankdata


def compute_dynamic_bollinger_bands(
    close: pd.Series,
    window: int = 20,
    k0: float = 2.0,
    alpha: float = 0.1,
    volatility_energy: pd.Series = None,
) -> pd.DataFrame:
    """
    P001 - Dynamic Bollinger Bands (Rules A1, A2, B1, C1, E2)

    Returns DataFrame with columns:
        ['upper_band', 'middle_band', 'lower_band', 'bandwidth']
    """
    if volatility_energy is None:
        volatility_energy = pd.Series(0, index=close.index)
    sma = close.rolling(window).mean()
    std = close.rolling(window).std(ddof=0)

    k_t = k0 * (1.0 + alpha * volatility_energy.fillna(0.0))
    upper = sma + k_t * std
    lower = sma - k_t * std
    bandwidth = (upper - lower) / sma

    return pd.DataFrame(
        {
            "upper_band": upper,
            "middle_band": sma,
            "lower_band": lower,
            "bandwidth": bandwidth,
        }
    )


def _percentile_series(x: pd.Series, window: int) -> pd.Series:
    """Helper: rolling percentile rank"""
    def _pct(arr):
        # percentile rank of last element within window
        ranks = rankdata(arr, method="average")
        return 100.0 * ranks[-1] / len(ranks)

    return x.rolling(window).apply(_pct, raw=False)


def compute_bandwidth_percentile_and_expansion(
    bandwidth: pd.Series,
    window: int = 20,
    expansion_lookback: int = 5,
) -> pd.DataFrame:
    """
    P002 - Bandwidth Percentile + Expansion (Rules A2, C1, E2)

    Returns DataFrame with columns:
        ['bw_percentile', 'expansion_rate']
    """
    bw_pct = _percentile_series(bandwidth, window)
    prev = bandwidth.shift(expansion_lookback)
    expansion_rate = (bandwidth - prev) / prev.replace(0, np.nan)

    return pd.DataFrame(
        {
            "bw_percentile": bw_pct,
            "bw_pct": bw_pct, # Alias for DSL usage (matches primitive alias)
            "expansion_rate": expansion_rate,
        }
    )


def compute_volume_ratio(
    volume: pd.Series,
    window: int = 20,
) -> pd.Series:
    """
    P003 - Volume Ratio (Rules A1, C1, D2)

    Returns Series: volume_ratio
    """
    sma_vol = volume.rolling(window).mean()
    return volume / sma_vol


def compute_spread_friction_ratio(
    high: pd.Series = None,
    low: pd.Series = None,
    spread: pd.Series = None,
    n: int = 20,
    atr_norm: pd.Series = None,
    vol_ratio: pd.Series = None,
    bandwidth: pd.Series = None,
    event_flag: pd.Series = None,
    theta0: float = 1.0,
    a: float = 0.1,
    b: float = 0.1,
    c: float = 0.05,
    d: float = 0.2,
    theta_min: float = 0.5,
    theta_max: float = 2.0,
    n_bars: int = None,  # Alias for n
) -> pd.DataFrame:
    """
    P004 - Spread Friction Ratio + Dynamic Î¸(t) (Rule E1 + THE SPREAD RULE)

    Returns DataFrame with columns:
        ['avg_range', 'friction_ratio', 'theta_dynamic', 'exec_allow']
    """
    # Handle n_bars alias
    if n_bars is not None:
        n = n_bars
    
    # Handle missing required inputs
    if high is None or low is None:
        return pd.DataFrame({
            "avg_range": pd.Series([1.0]),
            "friction_ratio": pd.Series([0.5]),
            "theta_dynamic": pd.Series([1.0]),
            "exec_allow": pd.Series([1]),
        })
    
    # Default spread to 0 if not provided
    if spread is None:
        spread = pd.Series([0.01] * len(high))
    
    # Default optional series
    if atr_norm is None:
        atr_norm = pd.Series([0.01] * len(high))
    if vol_ratio is None:
        vol_ratio = pd.Series([1.0] * len(high))
    if bandwidth is None:
        bandwidth = pd.Series([0.02] * len(high))
    if event_flag is None:
        event_flag = pd.Series([0.0] * len(high))
    
    avg_range = (high - low).rolling(n).mean()

    z_atr = (atr_norm - atr_norm.rolling(n).mean()) / atr_norm.rolling(n).std(ddof=0)
    z_vol = (vol_ratio - vol_ratio.rolling(n).mean()) / vol_ratio.rolling(n).std(ddof=0)
    z_bw = (bandwidth - bandwidth.rolling(n).mean()) / bandwidth.rolling(n).std(ddof=0)

    z_atr = z_atr.fillna(0.0)
    z_vol = z_vol.fillna(0.0)
    z_bw = z_bw.fillna(0.0)
    event_flag = event_flag.fillna(0.0)

    theta = theta0 + a * z_atr + b * z_vol - c * z_bw - d * event_flag
    theta = theta.clip(theta_min, theta_max)

    friction_ratio = spread / avg_range.replace(0, np.nan)
    exec_allow = (friction_ratio < theta).astype(int)

    return pd.DataFrame(
        {
            "avg_range": avg_range,
            "friction_ratio": friction_ratio,
            "theta_dynamic": theta,
            "exec_allow": exec_allow,
        }
    )


def compute_gap_risk_score(
    event_flag: pd.Series = None,
    atr_spike: pd.Series = None,
    bw_expansion: pd.Series = None,
    late_day_flag: pd.Series = None,
    w_event: float = 0.3,
    w_atr: float = 0.25,
    w_bw: float = 0.25,
    w_late: float = 0.2,
    g_crit: float = 0.8,
) -> pd.DataFrame:
    """
    P005 - Gap Risk Score G(t) (Rule E1 Override)

    Returns DataFrame with columns:
        ['gap_risk_score', 'risk_override']
    """
    # Handle None inputs
    if event_flag is None:
        event_flag = pd.Series([0.0])
    if atr_spike is None:
        atr_spike = pd.Series([0.0])
    if bw_expansion is None:
        bw_expansion = pd.Series([0.0])
    if late_day_flag is None:
        late_day_flag = pd.Series([0.0])
    
    event_flag = event_flag.fillna(0.0)
    atr_spike = atr_spike.fillna(0.0)
    bw_expansion = bw_expansion.fillna(0.0)
    late_day_flag = late_day_flag.fillna(0.0)

    g = (
        w_event * event_flag
        + w_atr * atr_spike
        + w_bw * bw_expansion
        + w_late * late_day_flag
    )
    g = g.clip(0.0, 1.0)
    risk_override = (g >= g_crit).astype(int)

    return pd.DataFrame(
        {
            "gap_risk_score": g,
            "risk_override": risk_override,
        }
    )


def compute_iv_confidence(
    lag_minutes: pd.Series,
    lambda_decay: float,
) -> pd.Series:
    """
    P006 - IV Confidence (Lag-Aware) (Rules A2, C1, C2, D2, E2, E3)

    Returns Series: iv_confidence
    """
    lag_minutes = lag_minutes.fillna(0.0)
    return np.exp(-lambda_decay * lag_minutes)


def compute_mtf_consensus(
    signal_1m: pd.Series,
    signal_5m: pd.Series,
    signal_15m: pd.Series,
    w_1m: float,
    w_5m: float,
    w_15m: float,
) -> pd.Series:
    """
    P007 - Multi-Timeframe Consensus (Rules A1, C1, E2)

    Returns Series: mtf_consensus in [-1, 1]
    """
    s1 = signal_1m.fillna(0.0)
    s5 = signal_5m.fillna(0.0)
    s15 = signal_15m.fillna(0.0)
    consensus = (w_1m * s1 + w_5m * s5 + w_15m * s15) / (w_1m + w_5m + w_15m)
    return consensus.clip(-1.0, 1.0)
