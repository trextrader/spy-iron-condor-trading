{
  "permissions": {
    "allow": [
      "Bash(ls:*)",
      "WebFetch(domain:www.reddit.com)",
      "WebFetch(domain:github.com)",
      "Bash(mamba create:*)",
      "WebFetch(domain:eci.intel.com)",
      "WebFetch(domain:pytorch-extension.intel.com)",
      "WebFetch(domain:developers.llamaindex.ai)",
      "WebFetch(domain:pypi.org)",
      "WebFetch(domain:www.intel.com)",
      "WebSearch",
      "Bash(where:*)",
      "Bash(pip install:*)",
      "Bash(python:*)",
      "Bash(dir \"C:\\\\SPYOptionTrader_test\\\\docs\\\\trading_rules\" /b)",
      "Bash(test:*)",
      "Bash(dot:*)",
      "Bash(dir:*)",
      "Bash(powershell \"Get-ChildItem *.png | Select-Object Name, Length, LastWriteTime | Format-Table -AutoSize\")",
      "Bash(git add:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfix\\(mamba2\\): Address model collapse with explicit ENTRY/EXIT heads\n\nCritical fixes for Mamba2 model collapse \\(constant outputs\\):\n\n1. Explicit ENTRY/EXIT Heads \\(condor_brain.py\\)\n   - CondorExpertHead outputs 10 params \\(was 8\\)\n   - entry_logit \\(idx 8\\), exit_logit \\(idx 9\\) as raw logits\n   - No longer derived from confidence scalar\n\n2. Realistic Training Targets \\(train_condor_brain.py\\)\n   - Targets vary by IVR/RSI/ADX \\(not constants\\)\n   - Entry/exit incorporate friction gate \\(Rule #14\\):\n     - exec_allow, friction_ratio, gap_risk_score\n   - Prevents model from learning constant 0.5\n\n3. Anti-Collapse Loss \\(condor_brain.py\\)\n   - Entropy regularization for probability heads\n   - Variance penalty if batch output variance too low\n   - BCEWithLogitsLoss for entry/exit supervision\n\n4. Feature-Group Dropout \\(condor_brain.py\\)\n   - New FeatureGroupDropout module\n   - Drops entire feature groups \\(15% prob recommended\\)\n   - Forces redundancy learning\n\n5. Variance Monitoring \\(training_monitor.py\\)\n   - compute_head_variance\\(\\) tracks per-head variance\n   - check_variance_collapse\\(\\) warns if < threshold\n   - Early detection of training collapse\n\n6. Temporal Attribution \\(export_learned_conditions.py\\)\n   - 7 temporal aggregations per feature\n   - _last, _mean, _std, _min, _max, _last5, _slope\n   - Better captures sequence model patterns\n\n7. Training Script \\(scripts/lightning_train_4runs.sh\\)\n   - 4 experiments for Lightning AI T4\n   - Runs 1-2: No diffusion\n   - Runs 3-4: With diffusion\n   - 100K rows, d_model=512, layers=16\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git push:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfix\\(train\\): Handle variable model outputs when diffusion enabled\n\nModel returns variable-length tuple when use_diffusion=True.\nFixed unpacking in both training and validation loops to extract\nonly outputs and regime_probs regardless of tuple length.\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfix\\(moe\\): Use CondorExpertHead.NUM_OUTPUTS \\(10\\) for TopKMoE output_dim\n\nMoE head was hardcoded to 8 outputs, causing shape mismatch with\n10-dimensional targets. Now uses constant from CondorExpertHead.\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")"
    ]
  }
}
